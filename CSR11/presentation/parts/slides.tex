\begin{frame}
	\frametitle{Goldreich's function}
	$f:\{0, 1\}^n \rightarrow \{0, 1\}^n$

    \pause

    \begin{columns}
    	\begin{column}{5.5cm}
            \input{pics/function_graph.tex}
        \end{column}

        \pause
        \pause
        \begin{column}{5.5cm}
            \begin{itemize}
	            \item $G(X, Y, E)$ is a bipartite graph;
            	\pause
                \item $\forall y \in Y ~~ deg(y) = d$
            	\pause
            	\item $d$ is a constant.
            \end{itemize}
        \end{column}
	\end{columns}
    
	\pause

    Goldreich's conjecture:
    \begin{itemize}
	    \item $P$ is a random predicate;
    	\item $G$ is an expander;
    \end{itemize}
    then function $f$ is a one-way.

    \pause
    \begin{itemize}
	    \item $f$ is computed by constant depth circuit;
    	\pause
	    \item{} [Applebaum, Ishai, Kushilevitz~2006] If one-way
		    functions exist then there is a one-way function that can
            be computed by constant depth circuit.
    \end{itemize}
\end{frame}

\begin{frame}
	\frametitle{DPLL algorithms}

   	\input{pics/tree.tex}
    
	\pause
    \pause
    \pause
    \pause
    \pause
    \begin{itemize}
        \item Heuristic $\mathbf{A}$ chooses a variable for splitting.
    	\pause
	    \item Heuristic $\mathbf{B}$ chooses first value.
    	\pause
    	\item Simplification rules:
	    \begin{itemize}
            \item unit clause elimination;
        	\item pure literal rule.
    	\end{itemize}
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Lower bounds for DPLL algorithms}

    \pause
	\begin{itemize}
		\item Unsatisfiable formulas
		\begin{itemize}
            \item{} Exponential lower bounds for resolution refutations
				of unsatisfiable formulas translate to backtracking
                algorithms.
			\item{} [Tseitin, 1968] ... [Pudlak, Implagliazzo, 2000].
		\end{itemize}
        \pause
		\item Satisfiable formulas
		\begin{itemize}
			\item If $\bf P = NP$ then there are no superpolynomial
		        lower bounds for backtracking algorithms since
                heuristic $\mathbf{B}$ may choose correct value.
            \pause
			\item Inverting of functions corresponds to satisfiable
		        formulas.
            \pause
            \item{} [Nikolenko~2002], [Achilioptas, Beame, Molloy~2003-2004]
				exponential lower bound for specific backtracking
                algorithms.
            \item{} [Alekhnovich, Hirsch, Itsykson~2005] Exponential lower bound 
				for myopic and drunken algorithms.
            \pause
            \item{}  Exponential lower bound 
		for inversion of Goldreich's function by myopic [J. Cook et al.~2009] 
		and drunken [Itsykson~2010] algorithms.
%            \item{}  Exponential lower bound 
%				for inversion of Goldreich's function by drunken algorithms.
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Drunken and myopic algorithms}
    \pause

    \begin{definition}
        Drunken algorithms:
        \begin{itemize}
	        \item $\mathbf{A}$: any;
	        \item $\mathbf{B}$: random  50 : 50.
        \end{itemize}
    \end{definition}

    \pause
    \begin{definition}
        Myopic heuristic:
        \pause
        \begin{itemize}
	        \item sees structure of the formula;
        	\pause
        	\item doesn't see negation signs;
        	\item<6-> requests negations in $K = n^{1 - \epsilon}$ clause.
        \end{itemize}
    \end{definition}

    \pause
    $\begin{array}{l}
        (x_1 \vee x_3 \vee x_5) \\
        \alert<7->{(x_2 \vee x_3)} \\
        (x_2 \vee x_4 \vee x_5) \\
        \alert<7->{(x_1 \vee x_4 \vee x_6)} \\
    \end{array}
    \pause
    \pause
    \pause
    \Rightarrow
    \begin{array}{l}
        (x_1 \vee x_3 \vee x_5) \\
        (x_2 \vee \alert{\neg} x_3) \\
        (x_2 \vee x_4 \vee x_5) \\
        (x_1 \vee \alert{\neg} x_4 \vee x_6) \\
    \end{array}$
    
\end{frame}

\begin{frame}
    \frametitle{Myopic algorithms}

    \pause

    \begin{definition}
		Myopic algorithm:
        \begin{itemize}
	        \item $\mathbf{A}, \mathbf{B}$ are myopic heuristics.
        \end{itemize}
        
%        $K$ is a heuristic parameter.
	\end{definition}

    \pause

    \begin{itemize}
    	\item{} [Alekhnovich, Hirsch, Itsykson~2005]
            \begin{itemize}
	            \item $P$ is a linear predicate.
            	\item $G$ is a random graph.
            \end{itemize}
        \pause
        \item{} [J. Cook, Etesami, Miller, Trevisan~2009] 
            \begin{itemize}
                \pause
   	            \item $P = x_1 + x_2 + \dots + x_{d - 2} + x_{d - 1}x_{d}$.
	            \item In fact: $P = x_1 + x_2 + \dots + x_{d - k} +
            		Q(x_{d - k + 1}, \dots, x_d)$.
            \end{itemize}

            	\pause
                \begin{columns}            
            	    \begin{column}{4cm}
                	    Disadvantages:
		            	\pause
           		        \begin{itemize}
		   	            	\item $G$ is a random graph.
				           	\pause
        				   	\item $K$ is a constant.
            				\pause
				           	\item Too complicated proof.            
				        \end{itemize}
                    \end{column}
                        
                   	\begin{column}{4cm}
                       	In our work:
	            		\pause
       		            \begin{itemize}
	   	            		\item \alert{$G$ is based on expander.}
			            	\pause
       				    	\item \alert{$K = n^{1 - \epsilon}$.}
           					\pause
			            	\item \alert{``Simple'' proof}.
			            \end{itemize}
                    \end{column}
                \end{columns}
    \end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Our results}

	$P(x_1, \ldots, x_d) = x_1 \oplus x_2 \oplus \ldots \oplus
    x_{d - k} \oplus Q(x_{d - k + 1}, \ldots, x_d)$, $Q$ is an
    arbitrary, $k < d / 4$.

	\pause
	\begin{theorem}
		There exists \alert{an explicit} graph $G$ such that
		every myopic or drunken DPLL algorithm makes at least $2^{n^{\Omega(1)}}$
		steps on ``$f(x) = f(a)$'' for almost all $a \in \{0, 1\}^n$.
	\end{theorem}

    \pause
    \begin{itemize}
	    \item $G$ is based on expander instead of random graph.
    	\pause
	    \item For drunken algorithms the proof follows
    		[Itsykson, CSR-2010] 
    	\pause
	    \item For myopic 
    	\begin{itemize}
 	       \item we simplify previous proof and 
     	   \item $K = n^{1 - \epsilon}$
    	\end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Graph construction}

    $P(x_1, \ldots, x_d) = \alert<2-5>{x_1 \oplus x_2 \oplus \ldots \oplus x_{d - k}} \oplus 
	\alert<6->{Q(x_{d - k + 1}, \ldots, x_d)}$
    
    \pause
    \input{pics/construction_graph.tex}

    \begin{itemize}
	    \item $G$ is an expander;
   		\pause
        \pause
        \item $G + T$ has full rank. $\forall y \in Y \subset T, ~
		    deg(y) = 1$;
        \pause
        \begin{itemize}
	        \item $G + T$ is an expander.
        \end{itemize}
        \pause
        \item $R$ contains nonlinear edges. $|\{x \mid x \in X, ~ deg(x)
		    \ne 0\}| \le n^{\epsilon}$.
        \begin{itemize}
	        \item $G + T + R$ is an expander.
        	\pause
            \item Size of preimages no more than
				$2^{n^{\epsilon}}$.
        \end{itemize}
    \end{itemize}
    We can invert $f_{G + T + R, P}$ in time $poly(n) 2^{n^{\epsilon}}$,
	but this is still much! 
\end{frame}

\begin{frame}
	\frametitle{Plan of the proof}

	\begin{itemize}	       
		\pause
		\item Lower bounds for unsatisfiable formulas.
			\pause
            \begin{itemize}
	            \item $G$ is an expander.
	            \item $P$ is almost linear.
	            \item Lower bounds for resolution proofs
            \end{itemize}
		\pause
		\item With probability $1 - 2^{-\Omega(n)}$ after several steps
		        current formula becomes unsatisfiable.
            \pause
            \begin{itemize}
	            \item $G$ is an expander.
	            \item $f$ is almost bijection.
	            \item Myopic algorithm can't recognize different
		            absolute terms.
            \end{itemize}
	\end{itemize}
   
\end{frame}